{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS-396 Senior Projects I: Perpetual Work-in-Progress Status Report 3\n",
    "## Author: Joseph Jinn\n",
    "\n",
    "<br>\n",
    "\n",
    "### Note: I need more coffee..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Progress:\n",
    "\n",
    "Placeholder text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File header for run_generation_custom.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic command to suppress code cell output.\n",
    "%%acapture\n",
    "\"\"\"\n",
    "CS-396 Senior Project I\n",
    "Project: Huggingface-Transformers GPT2 Text Modeling and Prediction\n",
    "Advisor: Professor Kenneth Arnold\n",
    "Coordinator: Professor Keith VanderLinden\n",
    "Author: Joseph Jinn\n",
    "\n",
    "run_generation_custom.py defines and implements a bare-bones text modeling and prediction program using the GPT2\n",
    "    model and tokenizer.\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "Notes:\n",
    "\n",
    "https://github.com/dunovank/jupyter-themes\n",
    "(Jupyter Notebook Themes)\n",
    "https://towardsdatascience.com/bringing-the-best-out-of-jupyter-notebooks-for-data-science-f0871519ca29\n",
    "(useful additions for Jupyter Notebook)\n",
    "https://medium.com/@rbmsingh/making-jupyter-dark-mode-great-5adaedd814db\n",
    "(Jupyter dark-mode settings; my eyes are no longer bleeding...)\n",
    "https://github.com/ipython-contrib/jupyter_contrib_nbextensions\n",
    "(Jupyter extensions)\n",
    "https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html\n",
    "(PyTorch tutorial on character-level RNN)\n",
    "\n",
    "Enter this in Terminal (for use with jupyter-themes):\n",
    "jt -t monokai -f fira -fs 13 -nf ptsans -nfs 11 -N -kl -cursw 5 -cursc r -cellw 95% -T\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "Important files to reference:\n",
    "\n",
    "modeling_gpt2.py\n",
    " - The GPT2 model source code.\n",
    "\n",
    "tokenization_gpy2.py\n",
    " - The tokenizer class for the GPT2 model.\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "Reference Material to understand the Theoretical Foundation of GPT2:\n",
    "https://en.wikipedia.org/wiki/Language_model\n",
    "http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "\n",
    "It would also be helpful to have some concept about beam search… I’m not super-happy with what my Googling obtains but…\n",
    "https://en.wikipedia.org/wiki/Beam_search\n",
    "https://machinelearningmastery.com/beam-search-decoder-natural-language-processing/\n",
    "\n",
    "Also maybe helpful but don’t get distracted:\n",
    "the first 20 minutes or so of this (everything after that is details of training, skip it.)\n",
    "https://www.youtube.com/watch?v=Keqep_PKrY8\n",
    "https://medium.com/syncedreview/language-model-a-survey-of-the-state-of-the-art-technology-64d1a2e5a466\n",
    "https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf\n",
    "https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf\n",
    "http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "More Notes:\n",
    "\n",
    "- CTRL + M + L (while in command mode): Adds code cell line numbers (very useful for debugging)\n",
    "\n",
    "- Select code fragment --> right-click --> Execute selection in Python console (Alt + Shift + E)\n",
    "    - executes selected (highlighted) code without re-running entire file.\n",
    "\n",
    "- CTRL + Q (brings up API documentation in Pycharm)\n",
    "\n",
    "- CTRL + Space (brings up list of functions)\n",
    "\n",
    "- Shift + Escape (close API documentation panel)\n",
    "\"\"\"\n",
    "\n",
    "#########################################################################################\n",
    "#########################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # PyTorch.\n",
    "import sys # For sys.exit.\n",
    "\n",
    "# Import required packages and libraries.\n",
    "from tqdm import trange  # Instantly make your loops show a smart progress meter.\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the GPT2 model and tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################################################################################\n",
    "\n",
    "# Load the GPT2-model.\n",
    "model_class = GPT2LMHeadModel  # Specifies the model to use.\n",
    "tokenizer_class = GPT2Tokenizer  # Specifies the tokenizer to use for the model.\n",
    "tokenizer = tokenizer_class.from_pretrained('gpt2')  # Use pre-trained model.\n",
    "model = model_class.from_pretrained('gpt2')  # User pre-trained model.\n",
    "model.to('cpu')  # Specifies what machine to run the model on.\n",
    "model.eval()  # Specifies that the model is NOT in training mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra top \"k\" most likely words to follow previous words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "\n",
    "\n",
    "# noinspection DuplicatedCode,PyUnresolvedReferences\n",
    "def extract_top_k_tokens(filtered_logits, k_value):\n",
    "    \"\"\"\n",
    "    This function utilizes the torch.topk() function to choose the \"k\" most likely words.\n",
    "\n",
    "    torch.topk performs a similar function to Softmax and argmax.\n",
    "    Uses the words' \"scores\" to choose the top \"k\" most likely predicted words (tokens).\n",
    "\n",
    "    - torch.topk\n",
    "     - Returns the :attr:`k` largest elements of the given :attr:`input` tensor along a given dimension.\n",
    "\n",
    "    Non-statistical and probabilistic method, so results are deterministic (always the same).\n",
    "\n",
    "    Parameters:\n",
    "        filtered_logits - entire vocabulary with assigned scores from GPT2 model.\n",
    "        k_value - choose \"k\" top most likely words.\n",
    "\n",
    "    Return:\n",
    "        my_topk - top \"k\" word tokens as Tensors.\n",
    "    \"\"\"\n",
    "    topk_debug = False\n",
    "\n",
    "    # Return the top \"k\" most likely (highest score value) words in sorted order..\n",
    "    my_topk = torch.topk(filtered_logits, k=k_value, dim=1, sorted=True)\n",
    "    if topk_debug:\n",
    "        print(f\"My torch.topk object: {my_topk}\\n\")\n",
    "        print(f\"torch.topk indices: {my_topk.indices}\")\n",
    "        print(f\"torch.topk values: {my_topk.values}\\n\")\n",
    "\n",
    "    # https://stackoverflow.com/questions/34750268/extracting-the-top-k-value-indices-from-a-1-d-tensor\n",
    "    # https://stackoverflow.com/questions/53903373/convert-pytorch-tensor-to-python-list\n",
    "\n",
    "    # Indices = encoded words, Values = scores.\n",
    "    if topk_debug:\n",
    "        print(f\"\\nDecoded torch.topk indices: {[tokenizer.decode(idx) for idx in my_topk.indices.squeeze().tolist()]}\")\n",
    "        print(f\"\\nDecoded torch.topk values: {tokenizer.decode(my_topk.indices.squeeze().tolist())}\\n\")\n",
    "\n",
    "        print(f\"topk indices shape: {my_topk.indices.shape}\")\n",
    "        print(f\"topk indices shape after squeeze: {my_topk.indices.squeeze().shape}\")\n",
    "        print(f\"topk indices after squeeze: {my_topk.indices.squeeze()}\\n\")\n",
    "\n",
    "        # https://stackoverflow.com/questions/43328632/pytorch-reshape-tensor-dimension\n",
    "\n",
    "        print(f\"topk indices 1st element in Tensor: {my_topk.indices[0][0]}\")\n",
    "        print(f\"topk indices 1st element in Tensor shape: {my_topk.indices[0][0].shape}\")\n",
    "        print(f\"topk indices 1st element in Tensor with added dimension: {my_topk.indices[0][0].unsqueeze(0)}\")\n",
    "        print(f\"topk indices 1st element in Tensor with added dimension shape: \"\n",
    "              f\"{my_topk.indices[0][0].unsqueeze(0).shape}\\n\")\n",
    "\n",
    "    if topk_debug:\n",
    "        # Ghetto looping through topk indices.\n",
    "        for elements in my_topk.indices[0]:\n",
    "            if topk_debug:\n",
    "                print(f\"topk word: {elements}\")\n",
    "                print(f\"topk word shape: {elements.shape}\")\n",
    "                print(f\"topk word shape after un-squeezing: {elements.unsqueeze(0).unsqueeze(0).shape}\")\n",
    "\n",
    "            # Set each element as the next token for text prediction and generation.\n",
    "            next_token = elements.unsqueeze(0).unsqueeze(0)\n",
    "            if topk_debug:\n",
    "                print(f\"Next token shape: {next_token.shape}\")\n",
    "                print(f\"Next token: {next_token}\")\n",
    "                print(f\"Decoded next token(s): {tokenizer.decode(next_token.squeeze().tolist())}\\n\")\n",
    "\n",
    "    # Returns the Tensor array of the top \"k\" word tokens\n",
    "    return my_topk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate and output text predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "\n",
    "# noinspection DuplicatedCode,PyUnresolvedReferences\n",
    "def prediction_generation(context_tokens, generated, prediction_option):\n",
    "    \"\"\"\n",
    "    This function makes text prediction using the GPT2 model and outputs the results.\n",
    "\n",
    "    Parameters:\n",
    "       context_tokens - the encoded raw text string.\n",
    "       generated - context_tokens wrapped as a PyTorch Tensor.\n",
    "       prediction_option - 'auto' or 'interactive' text prediction option.\n",
    "    \"\"\"\n",
    "    import random  # Random number generator.\n",
    "\n",
    "    temperature = 1  # Default value.\n",
    "    iterations = 20  # Default value.\n",
    "    k_value = 3  # Top \"k\" words to choose.\n",
    "\n",
    "    if prediction_option == \"interactive\":\n",
    "        valid = False\n",
    "        while not valid:\n",
    "            print(f\"\\nNote: To terminate the program, enter 'exit' for any of the requested inputs.  \"\n",
    "                  f\"Once all inputs have received a value, the program will then terminate.\")\n",
    "\n",
    "            print(f\"\\nNote: Temperature is a hyper-parameter of LSTMs (and neural networks generally) used to control \"\n",
    "                  f\"the randomness of predictions by scaling the logits before applying softmax.\")\n",
    "            temperature = input(f\"Set temperature value to (real number > 0): \")\n",
    "\n",
    "            print(f\"\\nNote: This controls how many iterations to generate the top 'k' most likely word tokens based on \"\n",
    "                  f\"the preceding token, which controls the # of word tokens the predicted text will consist of.\")\n",
    "            iterations = input(f\"Set the number of text prediction iterations for current string to: (integer > 0): \")\n",
    "\n",
    "            print(f\"\\nNote: This controls the # of tokens returned by the torch.topk() greedy sampling function.\")\n",
    "            k_value = input(f\"Enter the 'k' value for top 'k' most likely word token generation (integer > 0): \")\n",
    "\n",
    "            if temperature == \"exit\" or iterations == \"exit\" or k_value == \"exit\":\n",
    "                print(f\"Terminating program...\")\n",
    "                quit()\n",
    "\n",
    "            try:\n",
    "                if float(temperature) > 0.0 and int(iterations) > 0 and int(k_value) > 0:\n",
    "                    valid = True\n",
    "                else:\n",
    "                    print(f\"Invalid value(s) detected! Please choose valid value(s)!\\n\")\n",
    "            except TypeError:\n",
    "                continue\n",
    "\n",
    "    generated_array = []  # List of \"generated\" PyTorch Tensor containing encoded word tokens.\n",
    "    token_score_array = []  # List of \"scores\" for each token in the current iteration of topk greedy sampling.\n",
    "\n",
    "    logits_debug = False\n",
    "    topk_debug = False\n",
    "    output_debug = False\n",
    "\n",
    "    # Create list of PyTorch Tensors containing encoded original raw text string.\n",
    "    # Create a list of word token score values initially set to 1.0.\n",
    "    for i in range(0, int(k_value)):\n",
    "        generated_array.append(generated)\n",
    "        token_score_array.append(1.)\n",
    "\n",
    "    chosen_generated = generated_array[0]  # For initial iteration.\n",
    "\n",
    "    ############################################################################################\n",
    "\n",
    "    with torch.no_grad():  # This specifies not to use stochastic gradient descent!\n",
    "        for _ in trange(int(iterations)):\n",
    "\n",
    "            # Note: Feeding the results back into the model is the beginnings of a beam search algorithm.\n",
    "            # Currently, randomly chooses one of the \"generated\" Tensors to feed back in.\n",
    "            if logits_debug:\n",
    "                print(f\"Original generated shape: {generated}\")\n",
    "                print(f\"Generated array element 0 shape: {generated_array[0]}\")\n",
    "                print(f\"token_score_array element 0 shape: {token_score_array[0]}\\n\")\n",
    "\n",
    "            if prediction_option == \"auto\":\n",
    "                chosen_generated = generated_array[random.randint(0, int(k_value) - 1)]\n",
    "\n",
    "            # Call to GPT2 model generates a Tensor object containing \"scores\" for the entire vocabulary.\n",
    "            outputs = model(input_ids=chosen_generated)\n",
    "            if logits_debug:\n",
    "                print(f\"Outputs shape: {list(outputs)[0].shape}\\n\")\n",
    "                print(f\"Outputs: {list(outputs)[0]}\\n\")  # Outputs is a tensor containing a lot of stuff...\n",
    "\n",
    "            next_token_logits = outputs[0][:, -1, :] / (float(temperature) if float(temperature) > 0 else 1.)\n",
    "            if logits_debug:\n",
    "                print(f\"Next token logits shape: {next_token_logits.shape}\\n\")\n",
    "                print(f\"Next token logits: {next_token_logits}\\n\")\n",
    "\n",
    "            filtered_logits = next_token_logits  # Set to default name from run_generation.py\n",
    "\n",
    "            ############################################################################################\n",
    "\n",
    "            # Call function to extract the top \"k\" word tokens based on their scores.\n",
    "            my_topk = extract_top_k_tokens(filtered_logits, int(k_value))\n",
    "\n",
    "            if prediction_option == \"auto\":\n",
    "                # Ghetto looping through topk indices.\n",
    "                counter = 0\n",
    "                for elements in my_topk.indices[0]:\n",
    "                    if topk_debug:\n",
    "                        print(f\"topk word: {elements}\")\n",
    "                        print(f\"topk word shape: {elements.shape}\")\n",
    "                        print(f\"topk word shape after un-squeezing: {elements.unsqueeze(0).unsqueeze(0).shape}\")\n",
    "\n",
    "                    # Set each element as the next token for text prediction and generation.\n",
    "                    next_token = elements.unsqueeze(0).unsqueeze(0)\n",
    "                    if topk_debug:\n",
    "                        print(f\"Next token shape: {next_token.shape}\")\n",
    "                        print(f\"Next token: {next_token}\")\n",
    "                        print(f\"Decoded next token(s): {tokenizer.decode(next_token.squeeze().tolist())}\\n\")\n",
    "\n",
    "                    # Concatenate the chosen token (predicted word) to the end of the tokenized (encoded) string.\n",
    "                    # Then, add to the array of \"generated\" PyTorch tensors by modifying the original generated.\n",
    "                    generated_array[counter] = (torch.cat((chosen_generated, next_token), dim=1))\n",
    "                    if topk_debug:\n",
    "                        print(f\"Generated shape: {chosen_generated.shape}\")\n",
    "                        print(f\"Generated: {chosen_generated}\")\n",
    "                        print(f\"Decoded 'generated' tokens: {tokenizer.decode(chosen_generated.squeeze().tolist())}\\n\")\n",
    "\n",
    "                    counter += 1\n",
    "\n",
    "                    ############################################################################################\n",
    "\n",
    "                    # Output the text prediction results.\n",
    "                    print(f\"Original raw text string: {tokenizer.decode(context_tokens)}\\n\")\n",
    "                    for gen in generated_array:\n",
    "                        out = gen\n",
    "                        if output_debug:\n",
    "                            print(f\"Contents of 'out': {out}\")\n",
    "\n",
    "                        # This line removes the original text but keeps appending the generated words one-by-one\n",
    "                        # (based on iteration length).\n",
    "                        out = out[:, len(context_tokens):].tolist()\n",
    "                        if output_debug:\n",
    "                            print(f\"Contents of 'out' after .tolist(): {out}\\n\")\n",
    "                            print(f\"Length of context tokens:{len(context_tokens)}\\n\")\n",
    "\n",
    "                        # Outputs the result of the text modeling and prediction.\n",
    "                        for o in out:\n",
    "                            # Decode - convert from token ID's back into English words.\n",
    "                            text = tokenizer.decode(o, clean_up_tokenization_spaces=True)\n",
    "                            #     text = text[: text.find(args.stop_token) if args.stop_token else None]\n",
    "                            print(f\"###############################################################################\")\n",
    "                            print(f\"Note: The '#' at the beginning and end delimit the start and end of the text.\")\n",
    "                            print(f\"Predicted text: #{text}#\")\n",
    "                            print(f\"###############################################################################\")\n",
    "\n",
    "            ############################################################################################\n",
    "\n",
    "            if prediction_option == \"interactive\":\n",
    "                chosen = False\n",
    "                while not chosen:\n",
    "                    print(f\"\\nEnter 'exit' or 'Exit' to terminate the program.\")\n",
    "                    print(f\"The top k={k_value} tokens are:\")\n",
    "                    print(f\"Note: The '#' are there to delimit the start and end of the token since tokens \"\n",
    "                          f\"can include '\\\\n' and other invisible characters.\")\n",
    "                    print(f\"Note: Type in the EXACT characters you see (or don't see), including whitespace, etc.\\n\")\n",
    "                    counter = 0\n",
    "                    for elements in my_topk.indices[0]:\n",
    "                        print(f\"Token {counter}: #{tokenizer.decode(elements.unsqueeze(0).tolist())}#\")\n",
    "\n",
    "                    choose_token = input(f\"\\nChoose a token to use for the next iteration of text prediction:\")\n",
    "\n",
    "                    if choose_token == \"exit\" or choose_token == \"Exit\":\n",
    "                        print(f\"Terminating program...\")\n",
    "                        quit()\n",
    "\n",
    "                    for elements in my_topk.indices[0]:\n",
    "                        if choose_token == str(tokenizer.decode(elements.unsqueeze(0).tolist())):\n",
    "                            next_token = elements.unsqueeze(0).unsqueeze(0)\n",
    "                            chosen_generated = (torch.cat((chosen_generated, next_token), dim=1))\n",
    "                            chosen = True\n",
    "                            break\n",
    "\n",
    "                ############################################################################################\n",
    "\n",
    "                # Output the text prediction results.\n",
    "                print(f\"Original raw text string: {tokenizer.decode(context_tokens)}\\n\")\n",
    "\n",
    "                out = chosen_generated\n",
    "                if output_debug:\n",
    "                    print(f\"Contents of 'out': {out}\")\n",
    "\n",
    "                # This line removes the original text but keeps appending the generated words one-by-one (based on\n",
    "                # iteration length).\n",
    "                out = out[:, len(context_tokens):].tolist()\n",
    "                if output_debug:\n",
    "                    print(f\"Contents of 'out' after .tolist(): {out}\\n\")\n",
    "                    print(f\"Length of context tokens:{len(context_tokens)}\\n\")\n",
    "\n",
    "                # Outputs the result of the text modeling and prediction.\n",
    "                for o in out:\n",
    "                    # Decode - convert from token ID's back into English words.\n",
    "                    text = tokenizer.decode(o, clean_up_tokenization_spaces=True)\n",
    "                    #     text = text[: text.find(args.stop_token) if args.stop_token else None]\n",
    "                    print(f\"###############################################################################\")\n",
    "                    print(f\"Note: The '#' at the beginning and end delimit the start and end of the text.\")\n",
    "                    print(f\"Predicted text: #{text}#\")\n",
    "                    print(f\"###############################################################################\")\n",
    "\n",
    "            ############################################################################################\n",
    "\n",
    "            # Store the scores for each token.\n",
    "            counter = 0\n",
    "            for elements in my_topk.values[0]:\n",
    "                token_score_array[counter] = elements.unsqueeze(0).unsqueeze(0)\n",
    "                if topk_debug:\n",
    "                    print(f\"topk word score: {elements}\")\n",
    "                    print(f\"topk word score shape: {elements.shape}\")\n",
    "                    print(f\"topk word score shape after un-squeezing: {elements.unsqueeze(0).unsqueeze(0).shape}\")\n",
    "                counter += 1\n",
    "\n",
    "\n",
    "#########################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The usual main function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main encodes the raw text string, wraps in PyTorch Tensor, and calls prediction_generation().\n",
    "    Executes forever until user enters \"exit\" or \"Exit\".\n",
    "\n",
    "    Parameters: None\n",
    "    Return: None\n",
    "    \"\"\"\n",
    "    main_debug = False\n",
    "    context_debug = False\n",
    "    num_samples = 1  # Default value.\n",
    "    user_option = \"auto\"\n",
    "\n",
    "    print(f\"Welcome to the GPT2 bare-bones run_generation.py test.\")\n",
    "    print(f\"Note: Enter 'exit' or 'Exit' to quit the program.\")\n",
    "\n",
    "    print(f\"Please choose between automated text prediction or interactive text prediction:\\n\"\n",
    "          f\"Automated chooses default hard-coded settings and proceeds on its own.\\n\"\n",
    "          f\"Interactive allows the user to choose the next token used in text prediction \"\n",
    "          f\"and adjust some other settings.\\n\")\n",
    "\n",
    "    repeat_query = True\n",
    "    while repeat_query:\n",
    "        user_option = input(f\"Type 'auto' or 'interactive'.\")\n",
    "\n",
    "        if user_option == \"exit\" or user_option == \"Exit\":\n",
    "            return\n",
    "        elif user_option != \"auto\" and user_option != \"interactive\":\n",
    "            repeat_query = True\n",
    "            print(f\"Unrecognized option - type 'auto' or 'interactive'!\")\n",
    "        else:\n",
    "            repeat_query = False\n",
    "\n",
    "    ############################################################################################\n",
    "\n",
    "    while True:\n",
    "        raw_text = \"\"\n",
    "        while len(raw_text) == 0:\n",
    "            raw_text = input(\"Enter a string: \")\n",
    "            if len(raw_text) == 0:\n",
    "                print(f\"Please enter something that is NOT a empty string!\")\n",
    "\n",
    "        # Quit the program.\n",
    "        if raw_text == \"exit\" or raw_text == \"Exit\":\n",
    "            print(f\"Terminating program execution.\")\n",
    "            break\n",
    "\n",
    "        # Encode raw text.\n",
    "        context_tokens = tokenizer.encode(raw_text, add_special_tokens=False)\n",
    "        if main_debug:\n",
    "            print(f\"Raw text: {raw_text}\\n\")\n",
    "            print(f\"Context tokens: {context_tokens}\\n\")\n",
    "\n",
    "        context = context_tokens  # Set to name as in run_generation.py\n",
    "\n",
    "        # Convert to a PyTorch Tensor object (numpy array).\n",
    "        context = torch.tensor(context, dtype=torch.long, device='cpu')\n",
    "        if context_debug:\n",
    "            print(f\"Context shape: {context.shape}\")\n",
    "            print(f\"Context converted to PyTorch Tensor object: {context}\\n\")\n",
    "\n",
    "        # Un-squeeze adds a dimension to the Tensor array.\n",
    "        # Repeat adds x-dimensions and repeats the Tensor elements y-times.\n",
    "        context = context.unsqueeze(0).repeat(num_samples, 1)\n",
    "        if context_debug:\n",
    "            print(f\"Context shape after 'un-squeeze': {context.shape}\")\n",
    "            print(f\"Context after 'un-squeeze': {context}\\n\")\n",
    "\n",
    "        generated = context  # Set to name as in run_generation.py\n",
    "\n",
    "        # Generate and output text prediction results.\n",
    "        prediction_generation(context_tokens, generated, user_option)\n",
    "        print(f\"Iterations for current string has ended.  Will request user enter new string.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Auto\" Mode program execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the GPT2 bare-bones run_generation.py test.\n",
      "Note: Enter 'exit' or 'Exit' to quit the program.\n",
      "Please choose between automated text prediction or interactive text prediction:\n",
      "Automated chooses default hard-coded settings and proceeds on its own.\n",
      "Interactive allows the user to choose the next token used in text prediction and adjust some other settings.\n",
      "\n",
      "Type 'auto' or 'interactive'.auto\n",
      "Enter a string: I am thinking of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # a#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: ##\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: ##\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # a#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # doing#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: ##\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # a#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # doing#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 1/20 [00:00<00:03,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going to#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # doing#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going to#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going to#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going with#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 2/20 [00:00<00:03,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back to#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going with#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back to#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going with#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back to#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back for#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 3/20 [00:00<00:03,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back for#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and looking#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back for#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and looking#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and re#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 4/20 [00:00<00:02,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and looking#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and re#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing some#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and re#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing some#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing it#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 5/20 [00:00<00:02,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing some#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing it#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a book#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing it#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a book#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a lot#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 6/20 [00:00<00:02,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little bit#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a book#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a lot#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little bit#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a lot#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little bit#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little research#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 7/20 [00:01<00:02,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more research#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little research#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more research#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more of#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little research#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more research#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more of#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 8/20 [00:01<00:01,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more of#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work with#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work with#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work.#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 9/20 [00:01<00:01,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work with#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work.#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on my#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work.#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on my#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on this#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 10/20 [00:01<00:01,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the project#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on my#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on this#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the project#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the game#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on this#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the project#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the game#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 11/20 [00:01<00:01,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other side#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the game#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other side#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other projects#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other side#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other projects#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 12/20 [00:01<00:01,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff.#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other projects#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff.#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff,#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff.#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff,#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff I#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 13/20 [00:02<00:01,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff,#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff I#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff.\n",
      "#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff I#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff.\n",
      "#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. It#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 14/20 [00:02<00:00,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I'm#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff.\n",
      "#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. It#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I'm#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I think#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. It#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I'm#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I think#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 15/20 [00:02<00:00,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am not#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I think#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am not#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am not#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am going#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 16/20 [00:02<00:00,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am going#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking about#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am going#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking about#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking more#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 17/20 [00:02<00:00,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of doing#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking about#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking more#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of doing#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of going#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking more#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of doing#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of going#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of getting#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 18/20 [00:02<00:00,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of doing a#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of going#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of getting#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of doing a#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of doing some#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of getting#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of doing a#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of doing some#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of doing more#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 19/20 [00:03<00:00,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of doing some more#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of doing some#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of doing more#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of doing some more#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of doing some of#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of doing more#\n",
      "###############################################################################\n",
      "Original raw text string: I am thinking of\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of doing some more#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of doing some of#\n",
      "###############################################################################\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # going back and doing a little more work on the other stuff. I am thinking of doing some other#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:03<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations for current string has ended.  Will request user enter new string.\n",
      "\n",
      "Enter a string: exit\n",
      "Terminating program execution.\n"
     ]
    }
   ],
   "source": [
    "#########################################################################################\n",
    "\n",
    "# Execute the program.\n",
    "# In Pycharm, select below and Run with \"Alt + Shift + E\" to avoid re-running entire fire and re-loading model every-time.\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "############################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Interactive\" Mode program execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the GPT2 bare-bones run_generation.py test.\n",
      "Note: Enter 'exit' or 'Exit' to quit the program.\n",
      "Please choose between automated text prediction or interactive text prediction:\n",
      "Automated chooses default hard-coded settings and proceeds on its own.\n",
      "Interactive allows the user to choose the next token used in text prediction and adjust some other settings.\n",
      "\n",
      "Type 'auto' or 'interactive'.interactive\n",
      "Enter a string: Today is\n",
      "\n",
      "Note: To terminate the program, enter 'exit' for any of the requested inputs.  Once all inputs have received a value, the program will then terminate.\n",
      "\n",
      "Note: Temperature is a hyper-parameter of LSTMs (and neural networks generally) used to control the randomness of predictions by scaling the logits before applying softmax.\n",
      "Set temperature value to (real number > 0): 1\n",
      "\n",
      "Note: This controls how many iterations to generate the top 'k' most likely word tokens based on the preceding token, which controls the # of word tokens the predicted text will consist of.\n",
      "Set the number of text prediction iterations for current string to: (integer > 0): 20\n",
      "\n",
      "Note: This controls the # of tokens returned by the torch.topk() greedy sampling function.\n",
      "Enter the 'k' value for top 'k' most likely word token generation (integer > 0): 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 'exit' or 'Exit' to terminate the program.\n",
      "The top k=5 tokens are:\n",
      "Note: The '#' are there to delimit the start and end of the token since tokens can include '\\n' and other invisible characters.\n",
      "Note: Type in the EXACT characters you see (or don't see), including whitespace, etc.\n",
      "\n",
      "Token 0: # the#\n",
      "Token 0: # a#\n",
      "Token 0: # an#\n",
      "Token 0: # not#\n",
      "Token 0: # when#\n",
      "\n",
      "Choose a token to use for the next iteration of text prediction: the\n",
      "Original raw text string: Today is\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # the#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 1/20 [00:30<09:44, 30.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 'exit' or 'Exit' to terminate the program.\n",
      "The top k=5 tokens are:\n",
      "Note: The '#' are there to delimit the start and end of the token since tokens can include '\\n' and other invisible characters.\n",
      "Note: Type in the EXACT characters you see (or don't see), including whitespace, etc.\n",
      "\n",
      "Token 0: # day#\n",
      "Token 0: # time#\n",
      "Token 0: # first#\n",
      "Token 0: # end#\n",
      "Token 0: # moment#\n",
      "\n",
      "Choose a token to use for the next iteration of text prediction: first\n",
      "Original raw text string: Today is\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # the first#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 2/20 [00:48<08:02, 26.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 'exit' or 'Exit' to terminate the program.\n",
      "The top k=5 tokens are:\n",
      "Note: The '#' are there to delimit the start and end of the token since tokens can include '\\n' and other invisible characters.\n",
      "Note: Type in the EXACT characters you see (or don't see), including whitespace, etc.\n",
      "\n",
      "Token 0: # time#\n",
      "Token 0: # day#\n",
      "Token 0: # year#\n",
      "Token 0: # of#\n",
      "Token 0: # week#\n",
      "\n",
      "Choose a token to use for the next iteration of text prediction: time\n",
      "Original raw text string: Today is\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # the first time#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 3/20 [00:59<06:17, 22.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 'exit' or 'Exit' to terminate the program.\n",
      "The top k=5 tokens are:\n",
      "Note: The '#' are there to delimit the start and end of the token since tokens can include '\\n' and other invisible characters.\n",
      "Note: Type in the EXACT characters you see (or don't see), including whitespace, etc.\n",
      "\n",
      "Token 0: # that#\n",
      "Token 0: # in#\n",
      "Token 0: # I#\n",
      "Token 0: # we#\n",
      "Token 0: # a#\n",
      "\n",
      "Choose a token to use for the next iteration of text prediction: that\n",
      "Original raw text string: Today is\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # the first time that#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 4/20 [01:05<04:36, 17.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 'exit' or 'Exit' to terminate the program.\n",
      "The top k=5 tokens are:\n",
      "Note: The '#' are there to delimit the start and end of the token since tokens can include '\\n' and other invisible characters.\n",
      "Note: Type in the EXACT characters you see (or don't see), including whitespace, etc.\n",
      "\n",
      "Token 0: # the#\n",
      "Token 0: # I#\n",
      "Token 0: # a#\n",
      "Token 0: # we#\n",
      "Token 0: # an#\n",
      "\n",
      "Choose a token to use for the next iteration of text prediction: I\n",
      "Original raw text string: Today is\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # the first time that I#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 5/20 [01:11<03:28, 13.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 'exit' or 'Exit' to terminate the program.\n",
      "The top k=5 tokens are:\n",
      "Note: The '#' are there to delimit the start and end of the token since tokens can include '\\n' and other invisible characters.\n",
      "Note: Type in the EXACT characters you see (or don't see), including whitespace, etc.\n",
      "\n",
      "Token 0: #'ve#\n",
      "Token 0: # have#\n",
      "Token 0: #'m#\n",
      "Token 0: # am#\n",
      "Token 0: # can#\n",
      "\n",
      "Choose a token to use for the next iteration of text prediction: have\n",
      "Original raw text string: Today is\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # the first time that I have#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 6/20 [01:16<02:38, 11.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 'exit' or 'Exit' to terminate the program.\n",
      "The top k=5 tokens are:\n",
      "Note: The '#' are there to delimit the start and end of the token since tokens can include '\\n' and other invisible characters.\n",
      "Note: Type in the EXACT characters you see (or don't see), including whitespace, etc.\n",
      "\n",
      "Token 0: # ever#\n",
      "Token 0: # been#\n",
      "Token 0: # seen#\n",
      "Token 0: # had#\n",
      "Token 0: # heard#\n",
      "\n",
      "Choose a token to use for the next iteration of text prediction: ever\n",
      "Original raw text string: Today is\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # the first time that I have ever#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 7/20 [01:25<02:15, 10.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 'exit' or 'Exit' to terminate the program.\n",
      "The top k=5 tokens are:\n",
      "Note: The '#' are there to delimit the start and end of the token since tokens can include '\\n' and other invisible characters.\n",
      "Note: Type in the EXACT characters you see (or don't see), including whitespace, etc.\n",
      "\n",
      "Token 0: # been#\n",
      "Token 0: # seen#\n",
      "Token 0: # had#\n",
      "Token 0: # heard#\n",
      "Token 0: # met#\n",
      "\n",
      "Choose a token to use for the next iteration of text prediction: seen\n",
      "Original raw text string: Today is\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # the first time that I have ever seen#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 8/20 [01:29<01:42,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 'exit' or 'Exit' to terminate the program.\n",
      "The top k=5 tokens are:\n",
      "Note: The '#' are there to delimit the start and end of the token since tokens can include '\\n' and other invisible characters.\n",
      "Note: Type in the EXACT characters you see (or don't see), including whitespace, etc.\n",
      "\n",
      "Token 0: # a#\n",
      "Token 0: # the#\n",
      "Token 0: # an#\n",
      "Token 0: # such#\n",
      "Token 0: # this#\n",
      "\n",
      "Choose a token to use for the next iteration of text prediction: such\n",
      "Original raw text string: Today is\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # the first time that I have ever seen such#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 9/20 [01:33<01:18,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 'exit' or 'Exit' to terminate the program.\n",
      "The top k=5 tokens are:\n",
      "Note: The '#' are there to delimit the start and end of the token since tokens can include '\\n' and other invisible characters.\n",
      "Note: Type in the EXACT characters you see (or don't see), including whitespace, etc.\n",
      "\n",
      "Token 0: # a#\n",
      "Token 0: # an#\n",
      "Token 0: # great#\n",
      "Token 0: # amazing#\n",
      "Token 0: # strong#\n",
      "\n",
      "Choose a token to use for the next iteration of text prediction: a\n",
      "Original raw text string: Today is\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # the first time that I have ever seen such a#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 10/20 [01:40<01:11,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 'exit' or 'Exit' to terminate the program.\n",
      "The top k=5 tokens are:\n",
      "Note: The '#' are there to delimit the start and end of the token since tokens can include '\\n' and other invisible characters.\n",
      "Note: Type in the EXACT characters you see (or don't see), including whitespace, etc.\n",
      "\n",
      "Token 0: # large#\n",
      "Token 0: # thing#\n",
      "Token 0: # beautiful#\n",
      "Token 0: # great#\n",
      "Token 0: # huge#\n",
      "\n",
      "Choose a token to use for the next iteration of text prediction: beautiful\n",
      "Original raw text string: Today is\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # the first time that I have ever seen such a beautiful#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 11/20 [01:45<00:58,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 'exit' or 'Exit' to terminate the program.\n",
      "The top k=5 tokens are:\n",
      "Note: The '#' are there to delimit the start and end of the token since tokens can include '\\n' and other invisible characters.\n",
      "Note: Type in the EXACT characters you see (or don't see), including whitespace, etc.\n",
      "\n",
      "Token 0: #,#\n",
      "Token 0: # and#\n",
      "Token 0: # woman#\n",
      "Token 0: # piece#\n",
      "Token 0: # image#\n",
      "\n",
      "Choose a token to use for the next iteration of text prediction: woman\n",
      "Original raw text string: Today is\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # the first time that I have ever seen such a beautiful woman#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 12/20 [01:54<00:57,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 'exit' or 'Exit' to terminate the program.\n",
      "The top k=5 tokens are:\n",
      "Note: The '#' are there to delimit the start and end of the token since tokens can include '\\n' and other invisible characters.\n",
      "Note: Type in the EXACT characters you see (or don't see), including whitespace, etc.\n",
      "\n",
      "Token 0: # in#\n",
      "Token 0: #.#\n",
      "Token 0: #,#\n",
      "Token 0: # and#\n",
      "Token 0: # with#\n",
      "\n",
      "Choose a token to use for the next iteration of text prediction: with\n",
      "Original raw text string: Today is\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # the first time that I have ever seen such a beautiful woman with#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 13/20 [01:59<00:47,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 'exit' or 'Exit' to terminate the program.\n",
      "The top k=5 tokens are:\n",
      "Note: The '#' are there to delimit the start and end of the token since tokens can include '\\n' and other invisible characters.\n",
      "Note: Type in the EXACT characters you see (or don't see), including whitespace, etc.\n",
      "\n",
      "Token 0: # a#\n",
      "Token 0: # such#\n",
      "Token 0: # her#\n",
      "Token 0: # the#\n",
      "Token 0: # so#\n",
      "\n",
      "Choose a token to use for the next iteration of text prediction: her\n",
      "Original raw text string: Today is\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # the first time that I have ever seen such a beautiful woman with her#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 14/20 [02:11<00:49,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 'exit' or 'Exit' to terminate the program.\n",
      "The top k=5 tokens are:\n",
      "Note: The '#' are there to delimit the start and end of the token since tokens can include '\\n' and other invisible characters.\n",
      "Note: Type in the EXACT characters you see (or don't see), including whitespace, etc.\n",
      "\n",
      "Token 0: # hair#\n",
      "Token 0: # beautiful#\n",
      "Token 0: # own#\n",
      "Token 0: # face#\n",
      "Token 0: # head#\n",
      "\n",
      "Choose a token to use for the next iteration of text prediction: face\n",
      "Original raw text string: Today is\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # the first time that I have ever seen such a beautiful woman with her face#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 15/20 [02:19<00:41,  8.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 'exit' or 'Exit' to terminate the program.\n",
      "The top k=5 tokens are:\n",
      "Note: The '#' are there to delimit the start and end of the token since tokens can include '\\n' and other invisible characters.\n",
      "Note: Type in the EXACT characters you see (or don't see), including whitespace, etc.\n",
      "\n",
      "Token 0: # covered#\n",
      "Token 0: # and#\n",
      "Token 0: # in#\n",
      "Token 0: # painted#\n",
      "Token 0: # so#\n",
      "\n",
      "Choose a token to use for the next iteration of text prediction: covered\n",
      "Original raw text string: Today is\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # the first time that I have ever seen such a beautiful woman with her face covered#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 16/20 [02:28<00:33,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 'exit' or 'Exit' to terminate the program.\n",
      "The top k=5 tokens are:\n",
      "Note: The '#' are there to delimit the start and end of the token since tokens can include '\\n' and other invisible characters.\n",
      "Note: Type in the EXACT characters you see (or don't see), including whitespace, etc.\n",
      "\n",
      "Token 0: # in#\n",
      "Token 0: # with#\n",
      "Token 0: #.#\n",
      "Token 0: # by#\n",
      "Token 0: #,#\n",
      "\n",
      "Choose a token to use for the next iteration of text prediction: in\n",
      "Original raw text string: Today is\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # the first time that I have ever seen such a beautiful woman with her face covered in#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 17/20 [02:34<00:22,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 'exit' or 'Exit' to terminate the program.\n",
      "The top k=5 tokens are:\n",
      "Note: The '#' are there to delimit the start and end of the token since tokens can include '\\n' and other invisible characters.\n",
      "Note: Type in the EXACT characters you see (or don't see), including whitespace, etc.\n",
      "\n",
      "Token 0: # makeup#\n",
      "Token 0: # a#\n",
      "Token 0: # lipstick#\n",
      "Token 0: # blood#\n",
      "Token 0: # her#\n",
      "\n",
      "Choose a token to use for the next iteration of text prediction: blood\n",
      "Original raw text string: Today is\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # the first time that I have ever seen such a beautiful woman with her face covered in blood#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 18/20 [02:42<00:15,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 'exit' or 'Exit' to terminate the program.\n",
      "The top k=5 tokens are:\n",
      "Note: The '#' are there to delimit the start and end of the token since tokens can include '\\n' and other invisible characters.\n",
      "Note: Type in the EXACT characters you see (or don't see), including whitespace, etc.\n",
      "\n",
      "Token 0: #.#\n",
      "Token 0: # and#\n",
      "Token 0: #,#\n",
      "Token 0: #.\"#\n",
      "Token 0: #,\"#\n",
      "\n",
      "Choose a token to use for the next iteration of text prediction: and\n",
      "Original raw text string: Today is\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # the first time that I have ever seen such a beautiful woman with her face covered in blood and#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 19/20 [02:48<00:07,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 'exit' or 'Exit' to terminate the program.\n",
      "The top k=5 tokens are:\n",
      "Note: The '#' are there to delimit the start and end of the token since tokens can include '\\n' and other invisible characters.\n",
      "Note: Type in the EXACT characters you see (or don't see), including whitespace, etc.\n",
      "\n",
      "Token 0: # her#\n",
      "Token 0: # with#\n",
      "Token 0: # blood#\n",
      "Token 0: # eyes#\n",
      "Token 0: # a#\n",
      "\n",
      "Choose a token to use for the next iteration of text prediction: her\n",
      "Original raw text string: Today is\n",
      "\n",
      "###############################################################################\n",
      "Note: The '#' at the beginning and end delimit the start and end of the text.\n",
      "Predicted text: # the first time that I have ever seen such a beautiful woman with her face covered in blood and her#\n",
      "###############################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [03:05<00:00,  9.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations for current string has ended.  Will request user enter new string.\n",
      "\n",
      "Enter a string: exit\n",
      "Terminating program execution.\n"
     ]
    }
   ],
   "source": [
    "#########################################################################################\n",
    "\n",
    "# Execute the program.\n",
    "# In Pycharm, select below and Run with \"Alt + Shift + E\" to avoid re-running entire fire and re-loading model every-time.\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "############################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
